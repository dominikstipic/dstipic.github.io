<!doctype html>
<head>
  <title>Dominik Stipić</title>
  <link rel="icon" href="favicon.ico" />
  <link rel="stylesheet" type="text/css" href="../css/style.css">
</head>
<body>
    <h2>Professional Background</h2>

    My name is Dominik Stipić I graduated with a computer science degree from the Faculty of Electrical Engineering and Computing in Zagreb. 
    Professionaly I'm interested in the data science, natural language processing, machine learning and big data applied to the social and organizational networks.  


<p>On my studies my mentor was <a href="https://www.zemris.fer.hr/~ssegvic/">prof. dr. Siniša Šegvić</a>. 
   During that time I created two theses which focused on the intersection between machine learning and computer vision:</p>

<p>Bachelor Thesis: <a href="https://www.zemris.fer.hr/~ssegvic/project/pubs/stipic22ms.pdf">Convolutional Models for Person Localization in Sport Broadcasts</a></p>

<p>This thesis tackled the challenge of automatically detecting football players in video footage.  To achieve this, I used:</p>

<ul>
  <li><b>State-of-the-art object detection:</b> I employed Facebook's Mask-RCNN, a powerful deep convolutional network.</li>
  <li><b>Real-world data:</b>  I trained the model using a 10-minute football match video with meticulously annotated player positions.</li>
  <li><b>Fine-tuning for domain specificity:</b> I adapted the Mask-RCNN model to excel in the context of sports broadcasts.</li>
  <li><b>Architectural advantage:</b> The model's architecture included a bilinear interpolation layer, which significantly improved accuracy by addressing discretization issues arising from the image-to-grid conversion process. This innovation gave the model a performance edge over other contemporary approaches.</li>
</ul>

The name of my master thesis was <a rel="stylesheet" href="https://www.zemris.fer.hr/~ssegvic/project/pubs/stipic19bs.pdf">Semantic segmentation of buildings in satellite imagery</a> 
which encompased the development of the deep learning data pipeline and research about domain adaptation methods, applied to images. The aim was to transfer features from one domain to another. 
To be more specific, I created a new dataset D' which is obtained by transferring image features from unannotated D2 to annotated D1 through adverserial learning tactics. 
We do this in order to reduce covariate shift which happens because model learned spurious features which doesn't have predictive power.

<br>
<br>
<img src="../figs/graph.jpg"></img>

<br>
<br>
In this figure, you can see a directed acyclic graph which describes data generation for one data example x in D. X is the union of the two sets of features, the target object feature(y) and environment features(d). Basically, in an ideal scenario, the model should ignore environment features and only focus on the target features. It shouldn't care if the cat is on the tree or on the grass, it should only detect a cat. Generally, these things are now very popular and casual inference field is dealing with this. I have worked for a semester in a startup whose goal was to produce end-to-end computer vision ML platform for detecting browser objects such us URL or SSL key in order to assess the plausibility of the phishing attack. The project encompassed the planning and execution of data collection steps, data processing, choosing the right model and empirically test them, implementing quantitative measures for assessing the model performance and to transform the annotations and data across different platforms and systems in order to align the different systems.

<br>
<br>

With my colleagues, I published one research article in the IEEE 7th International Conference on Data Science and Advanced Analytics at Sydney, Australia in an NLP field. 
The article can be found <a href="https://ieeexplore.ieee.org/document/9260074">here</a>. The goal of the paper was to pretrain the Transformer model for classifying the tweets in the bots/human category, do feature engineering of the dataset and exploratory data analysis with the goal
of describing our dataset and demonstrating some hidden relationships in it. In the paper, we used the Latent Dirichlet Allocation, LDA, which was used for the purpose of extracting topics or hidden topics which occur together. We introduced new features
such as emojis, links and hashtags indicators in order to increase the performance of the models. Besides that, we used the t-SNE methods for mapping the data from multidimensional space to 2D, in order to check how does introduction of these 
new features improves the scores. In the end, we tested the functioning of the shallow machine networks with the deep transformer architecture on the classification tasks and concluded that there is 
no substantial difference. 
<br>
<br>
<img src="../figs/nlp.jpg" width="600" height="400"></img>
<br>
<br>


Other experience where I was involved in the analytical research was during my traineeship in the <a rel="stylesheet" href="https://www.ecb.europa.eu/home/html/index.en.html">European Central Bank</a>. Some of the tasks on which I worked were:
<ul>
    <li>Monitoring and analysing the performance of the Eurosystem monetary policy implementation framework and contributing to the preparation of policy proposals for its improvement</li>
    <li>Analyzing the reserve requirements and supply of reserves of the commercial banking sector: <a href="../html/essays/floor.html">link</a></li>
    <li>Helping maintain and enhance the Eurosystem market operation framework on a policy, operational, and technical level by performing data analysis activities, testing software and improving internal business intelligence reporting</li>
    <li>Contributing and enhancing the econometrical research for testing the effect of the liquidity injection on the supervisory regulatory measures</li>
    <li>Monitoring and assessing the financial eligibility of monetary policy counterparties and contributing to the analysis of topics such as minimum reserve requirements, targeted longer-term refinancing operations, emergency liquidity assistance and Eurosystem balance sheet items</li>
</ul>   



<br>
<br>
<h2>Other</h2> 
Generally, I have experience and knowledge working on end-to-end software engineering projects using mostly Java and Python languages. I am compfortable with creating, managing and administrating the databases
with SQL. My aggregated experience with different skills, frameworks, libraries and other can be found on my <a href="../html/skills.html">personal skill page</a>. 
You can find more about software engineering projects on my personal <a href="https://github.com/dominikstipic/CV/blob/main/README.md">Github profile</a>

<br>
<br>
